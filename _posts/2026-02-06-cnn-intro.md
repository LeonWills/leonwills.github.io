---
title: 从全连接神经网络 (MLP) 到卷积神经网络 (CNN)：一种演进的视角

date: 2026-02-06 12:00:00 +0800

categories: [Machine Learning, Deep Learning]

tags: [dl, cnn, theory, notes]

math: true 

img_path: /assets/img/posts/

---

在深度学习的入门阶段，我们通常从全连接神经网络（Fully Connected Neural Network，简称 FCNN 或 MLP）开始。然而，当我们试图用 MLP 来处理图像时，很快就会遇到瓶颈。

为什么在计算机视觉领域，CNN（卷积神经网络）会取代 MLP 成为绝对的主流？这就需要我们从神经网络的设计原理说起。

这篇文章将带你回顾从 MLP 到 CNN 的思维演变过程。

## 1. 全连接神经网络 (MLP) 的困境

让我们回顾一下使用 MLP 处理图像的过程。假设我们要处理一张 **$100 \times 100$ 像素** 的灰度单通道图片，处理过程如下图所示

![img2MLP_ch](../assets/img/posts/img2MLP_ch.png)



按照上图所示的对图像的处理，会有如下几个问题

- ##### **破坏空间结构**

​		MLP 接受的输入必须是一维向量。因此，我们必须先将 $100 \times 100$ 的二维矩阵进行 `Flatten`（展平）操作，变成一个长度为 $10,000$ 的向量。

​		$$x \in \mathbb{R}^{10000}$$

​		**问题在于：** 这个操作直接破坏了图像的**空间结构**。在图像中，像素点与其上下左右的邻居是有紧密联系的（比如构成一条线或一个形状），但展平后，像素 $(0,0)$ 和 $(0,1)$ 在向量中相邻，但 $(0,0)$ 和 $(1,0)$ 却被隔得很远。

- ##### **参数爆炸**

​		假设我们的第一个隐藏层有 $1,000$ 个神经元。由于是“全连接”，输入层的每一个像素都要和隐藏层的每一个神经元相连。

​		权值参数 $W$ 的数量为：
​		$$10,000 \times 1,000 = 10,000,000$$

​		仅仅一层网络就需要 **1000 万个参数**！这会导致两个严重后果：

​			1. **计算量巨大**：训练极其缓慢。

​			2. **过拟合**：参数过多，而数据量通常不足，模型很容易死记硬背训练集。



---

## 2. 演进第一步：局部连接 (Local Connectivity)

如何解决参数过多的问题？我们可以从人类看图的方式中获取灵感。

![dog](../assets/img/posts/dog.png)

当我们判断图中有没有一只“狗”时，不需要一眼看完所有像素。我们可以先看局部：这里是不是像耳朵？那里是不是像眼睛？所以我们观察的是局部特征，且只需要图像主体所在的像素，而不需要图像背景。

一个很直觉的想法是，我们将图像主体（例如上图中的狗）从整张图像中裁剪出来出入到神经网络中，这样就能极大程度上减少输入的维度，进而减少网络的参数量。

但是，如何“裁剪”是一个大难题，因为存在以下问题：

1. 我们无法确定每张图像的主体在图像的什么位置，
	1. 我们无法提前知道图像主体的大小

##### 解决方案

​	对于以上的问题，我们先假设图像主体的大小不会大于某个尺度，即可以使用一个$$w*h$$大小的矩形框框出来。在此基础上，想要解决问题1，没有其他特殊的办法，只能遍历整张图像。![image-20260206221824224](../assets/img/posts/dog__box.png)

遍历方式为：使用一个$$w*h$$大小的矩形框从图像左上角向右和向下移动，每次移动$$stride$$长度的像素，每次移动后截取出该范围的图像。上图中不同颜色的矩形框就代表截取出来的多张图片。

> 尽管每次截取出来的图像存在重复的部分，但是为了将图像主体完整的截取出来，必须这么做，且$$stride$$还应在网络参数可接受的情况下尽可能小（$$stride$$越小，输入维度越大，网络参数越多）

我们将裁剪出来的多张图片作为网络的输入，但是这样并不没有减少网络的参数量，相反还可能导致参数量增加。我们该如何解决这个问题呢？

---

## 3. 演进第二步：权值共享 (Weight Sharing)



虽然每个神经元只看局部，但如果隐藏层有 $1,000$ 个神经元，每个神经元看不同的位置，且拥有自己独立的权重，参数量虽然减少了，但依然不少。

这里引入第二个关键思想：**平移不变性 (Translation Invariance)**。

* 如果图片左上角有一个圆形，我们需要一个“圆形检测器”。
* 如果图片右下角有一个圆形，我们依然需要这个“圆形检测器”。

既然如此，为什么不让这两个位置共享同一个检测器（权重）呢？

**操作方法：**
我们设计一个 $3 \times 3$ 或 $5 \times 5$ 的小窗口（Filter），让它在整张大图上滑动。无论滑到哪里，都使用同一组权重进行计算。

这就是 **卷积 (Convolution)** 的本质。

*(建议此处插入你生成的“滑动窗口/卷积示意图”)*

_图 2：从网格划分到滑动窗口卷积，利用权值共享大大减少了参数_

---

## 4. 演进第三步：多通道 (Multi-channel)

一组权重（一个卷积核）只能提取一种特征（比如垂直边缘）。但图片是很复杂的，我们需要同时提取垂直边缘、水平边缘、色彩特征等。

**解决方案：**
我们不只用一个卷积核，而是用一组卷积核（例如 64 个）。
* Kernel 1 负责找横线。
* Kernel 2 负责找竖线。
* ...

这样输出的结果就不再是一张图，而是一叠图（Feature Maps）。

---

## 5. 演进第四步：下采样 (Pooling)

在识别物体时，我们通常不关心某个特征的具体像素坐标，只关心“有没有这个特征”以及大致位置。

例如，识别数字“7”，我们只关心左上角有横线，右上角有折角，至于这个折角是在 $(15, 15)$ 还是 $(16, 16)$ 并不重要。

**操作方法：**
使用 **池化层 (Pooling Layer)**，比如 Max Pooling。它将 $2 \times 2$ 的区域合并为一个值（取最大值）。
* 减少了数据维度（降维）。
* 增强了模型的鲁棒性。

---

## 总结：从 MLP 到 CNN

现在的 CNN 架构，其实就是对 MLP 的一种**结构化约束**：

1.  **输入层**：不再展平，保留 $(H, W, C)$ 的三维结构。
2.  **隐藏层**：
    * **全连接** $\rightarrow$ **局部连接**（只关注局部特征）。
    * **独立权重** $\rightarrow$ **权值共享**（一个卷积核扫全图）。
3.  **输出层**：最后依然接入一个全连接层（或全局平均池化）来输出分类结果。

这种设计使得 CNN 在处理图像时，既保留了空间信息，又极大地降低了参数量，从而使得训练深层网络成为可能。

> 下一篇预告：我们将使用 PyTorch 手写一个简单的 CNN 来识别 MNIST 手写数字。
